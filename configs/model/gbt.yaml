_target_: rl.models.GBT
latent_dim: 8
p_x: 0.1
p_e: 0.1
learning_rate: 0.00001
weight_decay: 0.01
num_layers: 4
hidden_size: 356
heads: 4
checkpoint_callback: True
checkpoint_kwargs:
  monitor: loss/train
  mode: min